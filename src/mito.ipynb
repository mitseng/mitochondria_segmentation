{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"mito.ipynb","provenance":[],"toc_visible":true,"mount_file_id":"1oBoEyhyjf921X-6EL2TFTGOiZJcamnyo","authorship_tag":"ABX9TyP74OEr70UHtXn9NIMO/ymo"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B6gXYYMThuKf","executionInfo":{"status":"ok","timestamp":1607523416658,"user_tz":-480,"elapsed":1596,"user":{"displayName":"ll z","photoUrl":"","userId":"03192467932253482596"}},"outputId":"908ad31b-3172-4dc5-dca7-8f6250a0e328"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Wed Dec  9 14:16:57 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FtEGajq9iKGI","executionInfo":{"status":"ok","timestamp":1607523421500,"user_tz":-480,"elapsed":1596,"user":{"displayName":"ll z","photoUrl":"","userId":"03192467932253482596"}},"outputId":"0a467153-6073-4bcf-fd38-32391507372a"},"source":["import os\n","os.chdir('/content/drive/My Drive/GitHub/mitochondria_segmentation/src')\n","print(os.getcwd())\n","#print(os.listdir())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/GitHub/mitochondria_segmentation/src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HnsIZH13iyIo","outputId":"5d34e318-c555-4fdf-af75-f1613192aff3"},"source":["!python train.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Data loaded.\n","device: cuda:0\n","train.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  inputs = torch.tensor(inputs, dtype=torch.float32)\n","train.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  lables = torch.tensor(lables, dtype=torch.long)\n","[1, loss: 0.255239]\n","2.0 minutes per epoch.\n","[2, loss: 0.167220]\n","2.0 minutes per epoch.\n","[3, loss: 0.143845]\n","2.0 minutes per epoch.\n","[4, loss: 0.126218]\n","2.0 minutes per epoch.\n","[5, loss: 0.113263]\n","2.0 minutes per epoch.\n","[6, loss: 0.103518]\n","2.0 minutes per epoch.\n","[7, loss: 0.096109]\n","2.0 minutes per epoch.\n","[8, loss: 0.089331]\n","2.0 minutes per epoch.\n","[9, loss: 0.083198]\n","2.0 minutes per epoch.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4m0XYB6oAJz6"},"source":["!python predict.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LC5m-yMWM-45","executionInfo":{"status":"ok","timestamp":1607435216061,"user_tz":-480,"elapsed":4440,"user":{"displayName":"ll z","photoUrl":"","userId":"03192467932253482596"}},"outputId":"0d7ea713-9b62-48c0-f06b-dd157d0a9254"},"source":["!python messure.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'TP': 582689, 'TN': 11065829, 'FP': 19985, 'FN': 127977, 'acc': 0.9874571058485242, 'sn': 0.9668394521748059, 'sp': 0.9885671593736749, 'rc': 0.8199196246900783, 'f1': 0.8873391500660668, 'jac': 0.7974929206967474, 'dice': 0.8873391505626869}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_uT60yJ9Gue7","executionInfo":{"status":"ok","timestamp":1607524370707,"user_tz":-480,"elapsed":1844,"user":{"displayName":"ll z","photoUrl":"","userId":"03192467932253482596"}},"outputId":"e1dee4ed-e315-4601-c7b4-c05116ed7402"},"source":["!cat train.py"],"execution_count":4,"outputs":[{"output_type":"stream","text":["# -*- coding: utf-8 -*-\r\n","\"\"\"\r\n","Created on Fri Nov 13 22:23:58 2020\r\n","\r\n","@author: zll\r\n","\"\"\"\r\n","\r\n","\r\n","import torch\r\n","from Mito_Dataset import Mito_Dataset\r\n","from torch.utils.data import DataLoader\r\n","from model import U_Net\r\n","from time import time\r\n","\r\n","\r\n","# ******** Hyper Parameters ********\r\n","# epoches till stop\r\n","EPOCHES = 1000\r\n","# if there is pretrained parameters\r\n","PRETRAIN = False\r\n","# epoches trained\r\n","pre_epoch = 0\r\n","# path to save parameter file\r\n","save_path = './param_128/'\r\n","# pretrained model parameter\r\n","pretrained = save_path + 'param.pkl'\r\n","# batch size\r\n","batch_size = 128\r\n","# **********************************\r\n","\r\n","\r\n","dataset = Mito_Dataset()\r\n","data_loader = DataLoader(dataset, batch_size=batch_size)\r\n","print('Data loaded.')\r\n","\r\n","# use GPU if available\r\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n","print('device:', device)\r\n","\r\n","# new and init model\r\n","model = U_Net()\r\n","if PRETRAIN:\r\n","    model.load_state_dict(torch.load(pretrained, map_location=device))\r\n","model.to(device)  # copy model to GPU\r\n","\r\n","# loss function\r\n","criterion = torch.nn.CrossEntropyLoss().to(device)\r\n","# optimizer\r\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\r\n","\r\n","\r\n","# training\r\n","for epoch in range(pre_epoch + 1, pre_epoch + 1 + EPOCHES):\r\n","    start_time = time()\r\n","    running_loss = 0.0\r\n","    for i, data in enumerate(data_loader):\r\n","        # get input\r\n","        inputs, lables = data\r\n","        inputs = torch.tensor(inputs, dtype=torch.float32)\r\n","        lables = torch.tensor(lables, dtype=torch.long)\r\n","        lables = lables.squeeze(1)\r\n","        # copy data to GPU\r\n","        inputs, lables = inputs.to(device), lables.to(device)\r\n","        # set gradiant 0\r\n","        optimizer.zero_grad()\r\n","        # forwarding\r\n","        outputs = model(inputs)\r\n","        # compute loss\r\n","        loss = criterion(outputs, lables)\r\n","        # backwarding\r\n","        loss.backward()\r\n","        # optimizing\r\n","        optimizer.step()\r\n","        # print states info\r\n","        running_loss += loss.item() * batch_size\r\n","    # print epoch loss and time\r\n","    print('[%d, loss: %.6f]' % (epoch, running_loss / dataset.len))\r\n","    print((time() - start_time) // 60, 'minutes per epoch.')\r\n","    # save model every epoch every 10 epoch\r\n","    if epoch % 10 == 0:\r\n","        torch.save(model.state_dict(), save_path + 'param'+str(epoch)+'.pkl')\r\n"],"name":"stdout"}]}]}