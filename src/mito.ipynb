{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"mito.ipynb","provenance":[],"toc_visible":true,"mount_file_id":"1oBoEyhyjf921X-6EL2TFTGOiZJcamnyo","authorship_tag":"ABX9TyP74OEr70UHtXn9NIMO/ymo"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B6gXYYMThuKf","executionInfo":{"status":"ok","timestamp":1609766100293,"user_tz":-480,"elapsed":3256,"user":{"displayName":"ll z","photoUrl":"","userId":"03192467932253482596"}},"outputId":"4fb4cfff-9864-4a99-c24b-80590acd83bc"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mon Jan  4 13:14:57 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FtEGajq9iKGI","executionInfo":{"status":"ok","timestamp":1609766305713,"user_tz":-480,"elapsed":3735,"user":{"displayName":"ll z","photoUrl":"","userId":"03192467932253482596"}},"outputId":"971d2b3c-4448-471b-d494-39bf8ef7028a"},"source":["import os\n","os.chdir('/content/drive/My Drive/GitHub/mitochondria_segmentation/src')\n","print(os.getcwd())\n","#print(os.listdir())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/GitHub/mitochondria_segmentation/src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HnsIZH13iyIo","outputId":"c252b7db-2bea-433d-dcfc-f48c77123c88"},"source":["!python train.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Data loaded.\n","device: cuda:0\n","train.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  inputs = torch.tensor(inputs, dtype=torch.float32)\n","train.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  lables = torch.tensor(lables, dtype=torch.long)\n","[451, loss: 0.010783]\n","15.0 minutes per epoch.\n","[452, loss: 0.010769]\n","8.0 minutes per epoch.\n","[453, loss: 0.010756]\n","8.0 minutes per epoch.\n","[454, loss: 0.010743]\n","8.0 minutes per epoch.\n","[455, loss: 0.010729]\n","8.0 minutes per epoch.\n","[456, loss: 0.010717]\n","8.0 minutes per epoch.\n","[457, loss: 0.010704]\n","8.0 minutes per epoch.\n","[458, loss: 0.010691]\n","8.0 minutes per epoch.\n","[459, loss: 0.010678]\n","8.0 minutes per epoch.\n","[460, loss: 0.010665]\n","8.0 minutes per epoch.\n","[461, loss: 0.010653]\n","8.0 minutes per epoch.\n","[462, loss: 0.010640]\n","8.0 minutes per epoch.\n","[463, loss: 0.010627]\n","8.0 minutes per epoch.\n","[464, loss: 0.010615]\n","8.0 minutes per epoch.\n","[465, loss: 0.010602]\n","8.0 minutes per epoch.\n","[466, loss: 0.010590]\n","8.0 minutes per epoch.\n","[467, loss: 0.010577]\n","8.0 minutes per epoch.\n","[468, loss: 0.010565]\n","8.0 minutes per epoch.\n","[469, loss: 0.010552]\n","8.0 minutes per epoch.\n","[470, loss: 0.010540]\n","8.0 minutes per epoch.\n","[471, loss: 0.010528]\n","8.0 minutes per epoch.\n","[472, loss: 0.010515]\n","8.0 minutes per epoch.\n","[473, loss: 0.010503]\n","8.0 minutes per epoch.\n","[474, loss: 0.010491]\n","8.0 minutes per epoch.\n","[475, loss: 0.010479]\n","8.0 minutes per epoch.\n","[476, loss: 0.010467]\n","8.0 minutes per epoch.\n","[477, loss: 0.010455]\n","8.0 minutes per epoch.\n","[478, loss: 0.010443]\n","8.0 minutes per epoch.\n","[479, loss: 0.010431]\n","8.0 minutes per epoch.\n","[480, loss: 0.010419]\n","8.0 minutes per epoch.\n","[481, loss: 0.010407]\n","8.0 minutes per epoch.\n","[482, loss: 0.010395]\n","8.0 minutes per epoch.\n","[483, loss: 0.010384]\n","8.0 minutes per epoch.\n","[484, loss: 0.010372]\n","8.0 minutes per epoch.\n","[485, loss: 0.010361]\n","8.0 minutes per epoch.\n","[486, loss: 0.010350]\n","8.0 minutes per epoch.\n","[487, loss: 0.010338]\n","8.0 minutes per epoch.\n","[488, loss: 0.010327]\n","8.0 minutes per epoch.\n","[489, loss: 0.010315]\n","8.0 minutes per epoch.\n","[490, loss: 0.010304]\n","8.0 minutes per epoch.\n","[491, loss: 0.010293]\n","8.0 minutes per epoch.\n","[492, loss: 0.010282]\n","8.0 minutes per epoch.\n","[493, loss: 0.010271]\n","8.0 minutes per epoch.\n","[494, loss: 0.010260]\n","8.0 minutes per epoch.\n","[495, loss: 0.010249]\n","8.0 minutes per epoch.\n","[496, loss: 0.010238]\n","8.0 minutes per epoch.\n","[497, loss: 0.010227]\n","8.0 minutes per epoch.\n","[498, loss: 0.010216]\n","8.0 minutes per epoch.\n","[499, loss: 0.010206]\n","8.0 minutes per epoch.\n","[500, loss: 0.010195]\n","8.0 minutes per epoch.\n","[501, loss: 0.010184]\n","8.0 minutes per epoch.\n","[502, loss: 0.010174]\n","8.0 minutes per epoch.\n","[503, loss: 0.010164]\n","8.0 minutes per epoch.\n","[504, loss: 0.010154]\n","8.0 minutes per epoch.\n","[505, loss: 0.010143]\n","8.0 minutes per epoch.\n","[506, loss: 0.010133]\n","8.0 minutes per epoch.\n","[507, loss: 0.010123]\n","8.0 minutes per epoch.\n","[508, loss: 0.010113]\n","8.0 minutes per epoch.\n","[509, loss: 0.010103]\n","8.0 minutes per epoch.\n","[510, loss: 0.010093]\n","8.0 minutes per epoch.\n","[511, loss: 0.010084]\n","8.0 minutes per epoch.\n","[512, loss: 0.010074]\n","8.0 minutes per epoch.\n","[513, loss: 0.010064]\n","8.0 minutes per epoch.\n","[514, loss: 0.010055]\n","8.0 minutes per epoch.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4m0XYB6oAJz6","executionInfo":{"status":"ok","timestamp":1609766356316,"user_tz":-480,"elapsed":51214,"user":{"displayName":"ll z","photoUrl":"","userId":"03192467932253482596"}}},"source":["!python predict.py"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LC5m-yMWM-45","executionInfo":{"elapsed":2708,"status":"ok","timestamp":1608042792898,"user":{"displayName":"ll z","photoUrl":"","userId":"03192467932253482596"},"user_tz":-480},"outputId":"37c65e6b-fde0-456e-e983-f3fb140d7e0c"},"source":["!python messure.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'TP': 578879, 'TN': 11066714, 'FP': 19100, 'FN': 131787, 'acc': 0.9872091505262586, 'sn': 0.9680590789977558, 'sp': 0.9882317285143787, 'rc': 0.8145584564338229, 'f1': 0.8846998226031715, 'jac': 0.7932392027033311, 'dice': 0.8846998230994648}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_uT60yJ9Gue7","executionInfo":{"elapsed":1844,"status":"ok","timestamp":1607524370707,"user":{"displayName":"ll z","photoUrl":"","userId":"03192467932253482596"},"user_tz":-480},"outputId":"e1dee4ed-e315-4601-c7b4-c05116ed7402"},"source":["!cat train.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# -*- coding: utf-8 -*-\r\n","\"\"\"\r\n","Created on Fri Nov 13 22:23:58 2020\r\n","\r\n","@author: zll\r\n","\"\"\"\r\n","\r\n","\r\n","import torch\r\n","from Mito_Dataset import Mito_Dataset\r\n","from torch.utils.data import DataLoader\r\n","from model import U_Net\r\n","from time import time\r\n","\r\n","\r\n","# ******** Hyper Parameters ********\r\n","# epoches till stop\r\n","EPOCHES = 1000\r\n","# if there is pretrained parameters\r\n","PRETRAIN = False\r\n","# epoches trained\r\n","pre_epoch = 0\r\n","# path to save parameter file\r\n","save_path = './param_128/'\r\n","# pretrained model parameter\r\n","pretrained = save_path + 'param.pkl'\r\n","# batch size\r\n","batch_size = 128\r\n","# **********************************\r\n","\r\n","\r\n","dataset = Mito_Dataset()\r\n","data_loader = DataLoader(dataset, batch_size=batch_size)\r\n","print('Data loaded.')\r\n","\r\n","# use GPU if available\r\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n","print('device:', device)\r\n","\r\n","# new and init model\r\n","model = U_Net()\r\n","if PRETRAIN:\r\n","    model.load_state_dict(torch.load(pretrained, map_location=device))\r\n","model.to(device)  # copy model to GPU\r\n","\r\n","# loss function\r\n","criterion = torch.nn.CrossEntropyLoss().to(device)\r\n","# optimizer\r\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\r\n","\r\n","\r\n","# training\r\n","for epoch in range(pre_epoch + 1, pre_epoch + 1 + EPOCHES):\r\n","    start_time = time()\r\n","    running_loss = 0.0\r\n","    for i, data in enumerate(data_loader):\r\n","        # get input\r\n","        inputs, lables = data\r\n","        inputs = torch.tensor(inputs, dtype=torch.float32)\r\n","        lables = torch.tensor(lables, dtype=torch.long)\r\n","        lables = lables.squeeze(1)\r\n","        # copy data to GPU\r\n","        inputs, lables = inputs.to(device), lables.to(device)\r\n","        # set gradiant 0\r\n","        optimizer.zero_grad()\r\n","        # forwarding\r\n","        outputs = model(inputs)\r\n","        # compute loss\r\n","        loss = criterion(outputs, lables)\r\n","        # backwarding\r\n","        loss.backward()\r\n","        # optimizing\r\n","        optimizer.step()\r\n","        # print states info\r\n","        running_loss += loss.item() * batch_size\r\n","    # print epoch loss and time\r\n","    print('[%d, loss: %.6f]' % (epoch, running_loss / dataset.len))\r\n","    print((time() - start_time) // 60, 'minutes per epoch.')\r\n","    # save model every epoch every 10 epoch\r\n","    if epoch % 10 == 0:\r\n","        torch.save(model.state_dict(), save_path + 'param'+str(epoch)+'.pkl')\r\n"],"name":"stdout"}]}]}